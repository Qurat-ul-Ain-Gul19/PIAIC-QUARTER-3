{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Chapter8_8.1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qurat-ul-Ain-Gul19/PIAIC-QUARTER-3/blob/main/COL-Copy_of_Chapter8_8_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TZ5FHk5Ss6_"
      },
      "source": [
        "import numpy as np\n",
        "def reweight_distribution(original_distribution, temperature=0.5):\n",
        "  distribution = np.log(original_distribution) / temperature\n",
        "  distribution = np.exp(distribution)\n",
        "  return distribution / np.sum(distribution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "wRKJKHC9Z_2R",
        "outputId": "814d11dc-c3be-42f3-ac49-d9cee1122501"
      },
      "source": [
        "text = \"\"\"\n",
        "After being tested COVID positive on 2 April 2021, I was rushed to Pakistan\n",
        "Emirates Military Hospital (PEMH) Rawalpindi where I was admitted urgently,\n",
        "then followed by my wife, after two days. I would like to share the painful\n",
        "experience of symptoms related to the disease and how the wonderful and\n",
        "caring hospital staff took care of us. It is for the sake of posterity and letting\n",
        "the readers know about the good work being done by medical establishments\n",
        "run by Pakistan Armed Forces and about which very few people actually know\n",
        "about.\n",
        "My experience as a patient has\n",
        "touched me so deeply that I have\n",
        "been inspired to write this TRIBUTE,\n",
        "realising that not only are they the\n",
        "most unique but truly the HEROES\n",
        "against the monstrous enemy of the\n",
        "humanity.Covid-19 has brought a murderous and menacing holocaust of the size never\n",
        "been experienced in the history of mankind, except the Spanish Flu, affecting\n",
        "every nation across the globe. For once, one saw the human race coming\n",
        "forward to show camaraderie and unity to face the monster that has invaded\n",
        "every home in every nook and corner of the world. The mask, protective\n",
        "gloves and rest of the Corona protective gear has become a part of everyday\n",
        "apparel and standard SOP as part of our living. International air travel has\n",
        "reduced global village to abodes of isolation.\n",
        "Where the scientists have been trying to get to know the origins of the virus\n",
        "and find a breakthrough in treatment, it has been a challenge for the brave\n",
        "doctors, paramedics, nursing and logistics staff, who faced the pandemic, living\n",
        "and working in an environment that was overflowing with the “virus of death”.\n",
        "They never failed to live up to the expectations offering their lives in the\n",
        "process as the hospitals started overflowing with the suffering humanity,\n",
        "irrespective of sex and age. This type of human behavior had only been\n",
        "witnessed in natural calamities\n",
        "From the moment I got into the hospital, the practical application of terms\n",
        "“sacrifice” and “beyond the call of duty”, was visible all around. This is the kind\n",
        "of stuff I had experienced in raging tank battles during my early army life.\n",
        "As soon as I was into the hospital, I could feel a sense of urgency in everyone’s\n",
        "demeanour and despite heavy workload, lack of staff and minor inadequacies,\n",
        "the staff ably led by Brig Raja Khalid Mehmood, the Nephrologist and his highly\n",
        "efficient team of experienced doctors, nursing staff, paramedics and the\n",
        "logistics staff put in their best to attend to every patient in the best\n",
        "professional manner. The memory of the angelic faces of the entire hospital\n",
        "staff will always stay fresh in my mind, reminding me of the loving care, as one\n",
        "can only expect from one’s family. No amount of gratitude will suffice in\n",
        "acknowledging their deeds.\n",
        "While I was in the hospital, I kept learning of fatalities taking place on daily\n",
        "basis, which in itself is so depressing for any patient. Amongst them was one\n",
        "of the noblest and revered souls, Lt Col Mahjabeen Riaz, Wife of Lt Gen Riaz\n",
        "Chohan, a former Surgeon General of Pakistan Army. May Allah rest her soul in\n",
        "peace and in heaven. Like me and my wife, they were also hospitalized\n",
        "together. I have known Lt Gen Riaz Chohan, since my youth.\n",
        "\n",
        "\n",
        "\"\"\".lower()\n",
        "print(len(text))\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nafter being tested covid positive on 2 april 2021, i was rushed to pakistan\\nemirates military hospital (pemh) rawalpindi where i was admitted urgently,\\nthen followed by my wife, after two days. i would like to share the painful\\nexperience of symptoms related to the disease and how the wonderful and\\ncaring hospital staff took care of us. it is for the sake of posterity and letting\\nthe readers know about the good work being done by medical establishments\\nrun by pakistan armed forces and about which very few people actually know\\nabout.\\nmy experience as a patient has\\ntouched me so deeply that i have\\nbeen inspired to write this tribute,\\nrealising that not only are they the\\nmost unique but truly the heroes\\nagainst the monstrous enemy of the\\nhumanity.covid-19 has brought a murderous and menacing holocaust of the size never\\nbeen experienced in the history of mankind, except the spanish flu, affecting\\nevery nation across the globe. for once, one saw the human race coming\\nforward to show camaraderie and unity to face the monster that has invaded\\nevery home in every nook and corner of the world. the mask, protective\\ngloves and rest of the corona protective gear has become a part of everyday\\napparel and standard sop as part of our living. international air travel has\\nreduced global village to abodes of isolation.\\nwhere the scientists have been trying to get to know the origins of the virus\\nand find a breakthrough in treatment, it has been a challenge for the brave\\ndoctors, paramedics, nursing and logistics staff, who faced the pandemic, living\\nand working in an environment that was overflowing with the “virus of death”.\\nthey never failed to live up to the expectations offering their lives in the\\nprocess as the hospitals started overflowing with the suffering humanity,\\nirrespective of sex and age. this type of human behavior had only been\\nwitnessed in natural calamities\\nfrom the moment i got into the hospital, the practical application of terms\\n“sacrifice” and “beyond the call of duty”, was visible all around. this is the kind\\nof stuff i had experienced in raging tank battles during my early army life.\\nas soon as i was into the hospital, i could feel a sense of urgency in everyone’s\\ndemeanour and despite heavy workload, lack of staff and minor inadequacies,\\nthe staff ably led by brig raja khalid mehmood, the nephrologist and his highly\\nefficient team of experienced doctors, nursing staff, paramedics and the\\nlogistics staff put in their best to attend to every patient in the best\\nprofessional manner. the memory of the angelic faces of the entire hospital\\nstaff will always stay fresh in my mind, reminding me of the loving care, as one\\ncan only expect from one’s family. no amount of gratitude will suffice in\\nacknowledging their deeds.\\nwhile i was in the hospital, i kept learning of fatalities taking place on daily\\nbasis, which in itself is so depressing for any patient. amongst them was one\\nof the noblest and revered souls, lt col mahjabeen riaz, wife of lt gen riaz\\nchohan, a former surgeon general of pakistan army. may allah rest her soul in\\npeace and in heaven. like me and my wife, they were also hospitalized\\ntogether. i have known lt gen riaz chohan, since my youth.\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzazffZ8UPTj"
      },
      "source": [
        "## Listing 8.2 Downloading and parsing the initial text file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkQFYt_kS4lN",
        "outputId": "5c84bc75-6f34-4412-93ef-272c6903d012"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "path = keras.utils.get_file('nietzsche.txt',\n",
        "                            origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "\n",
        "text = open(path).read().lower()\n",
        "print('Corpus length:', len(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "606208/600901 [==============================] - 0s 0us/step\n",
            "Corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJCYIbaqUh3K"
      },
      "source": [
        "## Listing 8.3 Vectorizing sequences of characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBJ611L4da0x"
      },
      "source": [
        "maxlen = 60\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Sk4X3fVd3QO",
        "outputId": "22f35068-43b6-4bcd-b248-3b2b0cfa0f45"
      },
      "source": [
        "\n",
        "print('Number of sequences:', len(sentences))\n",
        "chars = sorted(list(set(text)))\n",
        "print('Unique characters:', len(chars))\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "print('Vectorization...')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 200278\n",
            "Unique characters: 57\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbuET0_ZeYto",
        "outputId": "19b2264a-3467-4989-cbf4-b403b31e5ad1"
      },
      "source": [
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "\n",
        "y[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdHPeQbnUXzO"
      },
      "source": [
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1\n",
        "  y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj6obGInerxM",
        "outputId": "880ac61d-4fdf-4a4d-9867-278fd6e0a87b"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False,  True,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtBZbuADVODB"
      },
      "source": [
        "## Listing 8.4 Single-layer LSTM model for next-character prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN8Oce9_U-fM"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16yfGWheVWBr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVcMhC6tVSl1"
      },
      "source": [
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coKf816_V1et"
      },
      "source": [
        "## Listing 8.6 Function to sample the next character given the model’s predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdTI3vcTVZmu"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kNfDmCJWAmR"
      },
      "source": [
        "## Listing 8.7 Text-generation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA4s-ik7bB7v",
        "outputId": "3c3af400-b90a-4ae2-fc34-e1da7405ea57"
      },
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "\n",
        "model.fit(x, y, batch_size=128, epochs=10)\n",
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "generated_text = text[start_index: start_index + maxlen]\n",
        "print('--- Generating by Machine: \"' + generated_text + '\"')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1565/1565 [==============================] - 42s 6ms/step - loss: 2.2643\n",
            "Epoch 2/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.6310\n",
            "Epoch 3/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.5248\n",
            "Epoch 4/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.4761\n",
            "Epoch 5/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.4380\n",
            "Epoch 6/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.4117\n",
            "Epoch 7/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3971\n",
            "Epoch 8/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3811\n",
            "Epoch 9/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3738\n",
            "Epoch 10/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3623\n",
            "--- Generating by Machine: \"like the sun. and we foremost, we good europeans!\n",
            "\n",
            "244. ther\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CskxCYNQcimq",
        "outputId": "25320823-caf0-464c-f7e4-6b6cca7f2882"
      },
      "source": [
        "temperature = 0.5\n",
        "for i in range(400):\n",
        "    sampled = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(generated_text):\n",
        "      sampled[0, t, char_indices[char]] = 1.\n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = sample(preds, temperature)\n",
        "    next_char = chars[next_index]\n",
        "    generated_text += next_char\n",
        "    generated_text = generated_text[1:]\n",
        "    sys.stdout.write(next_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "e is there the present that it is say, the defection and discovered love of a dependent has seems to existence, to makes to be greated new to any one must be that it cannot been a present and self-destruction of the content of the for a man of the spirit and the belief in the free spirit to disself for the exception and stands a very one of the world is as the subjection the precipilition that sou"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G49RqUssV5i3",
        "outputId": "0827c5c9-b57c-4a4b-8374-7af7ce992af7"
      },
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "for epoch in range(1, 60):\n",
        "  print('epoch', epoch)\n",
        "  model.fit(x, y, batch_size=128, epochs=1)\n",
        "  start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "  generated_text = text[start_index: start_index + maxlen]\n",
        "  print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "  print('------ temperature:', temperature)\n",
        "  sys.stdout.write(generated_text)\n",
        "  for i in range(400):\n",
        "    sampled = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(generated_text):\n",
        "      sampled[0, t, char_indices[char]] = 1.\n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = sample(preds, temperature)\n",
        "    next_char = chars[next_index]\n",
        "    generated_text += next_char\n",
        "    generated_text = generated_text[1:]\n",
        "    sys.stdout.write(next_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3690\n",
            "--- Generating with seed: \"ssimilation of its nutriment. there are honestly meant trans\"\n",
            "epoch 2\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3601\n",
            "--- Generating with seed: \" and the sign of a despairing,\n",
            "mortally wearied soul, notwit\"\n",
            "epoch 3\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3533\n",
            "--- Generating with seed: \"rent series of feeling and thoughts, whereas it is\n",
            "unconscio\"\n",
            "epoch 4\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3475\n",
            "--- Generating with seed: \"l states being falsely\n",
            "viewed and his personality being sund\"\n",
            "epoch 5\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3425\n",
            "--- Generating with seed: \"rder of\n",
            "philosophers, such as will have other tastes and inc\"\n",
            "epoch 6\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3371\n",
            "--- Generating with seed: \"ropound an\n",
            "explanation, too, free from mythology: hence one \"\n",
            "epoch 7\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3324\n",
            "--- Generating with seed: \"ning to appear.\n",
            "\n",
            "3. having kept a sharp eye on philosophers,\"\n",
            "epoch 8\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3293\n",
            "--- Generating with seed: \"aps a\n",
            "prematureness or preliminariness, probably something o\"\n",
            "epoch 9\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3238\n",
            "--- Generating with seed: \"e beginning that in all nature there is no perfectly straigh\"\n",
            "epoch 10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3200\n",
            "--- Generating with seed: \"pated therein: that which in the end always\n",
            "prefers a handfu\"\n",
            "epoch 11\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3170\n",
            "--- Generating with seed: \"poets\n",
            "always know how to console themselves.\n",
            "\n",
            "\n",
            "34\n",
            "\n",
            "=for tran\"\n",
            "epoch 12\n",
            "  61/1565 [>.............................] - ETA: 9s - loss: 1.2588"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9PehOkAWmtn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}